{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f0d962d",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "####  Top Skills of DS ( Data Scientists) on GlassDoor and Indeed\n",
    "This program aims at presenting the top 10 skills of DS listed in job descriptions of glassdoor and indeed. For the detail background, deliverables and processes, please see the readme in this git."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26a90261",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T03:35:24.328888Z",
     "start_time": "2022-05-12T03:35:24.319464Z"
    }
   },
   "outputs": [],
   "source": [
    "### Load required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f31b039",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T09:35:47.913312Z",
     "start_time": "2022-05-12T09:35:47.893675Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Text preprocessing\n",
    "import os,re\n",
    "from bs4 import BeautifulSoup\n",
    "from langdetect import detect\n",
    "\n",
    "# Disable warning of 3 types\n",
    "import warnings\n",
    "\n",
    "#Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "# Other utils\n",
    "from tqdm import tqdm  # Progress bar\n",
    "\n",
    "# Azure text analytics service api\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "\n",
    "\n",
    "# aws comprehend\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "#EDA tools.\n",
    "import dtale\n",
    "\n",
    "# Geopy for location\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "# nlp text cleaning\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer # or LancasterStemmer, RegexpStemmer, SnowballStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba47d7e",
   "metadata": {},
   "source": [
    "### Pre-settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f079213",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T03:35:31.295991Z",
     "start_time": "2022-05-12T03:35:31.284166Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the width to show the column as much as possible.\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "# Disable 3 types of warning\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\",category=(FutureWarning))\n",
    "warnings.filterwarnings(\"ignore\",category=(RuntimeWarning))\n",
    "\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9415bf",
   "metadata": {},
   "source": [
    "### data cleaning\n",
    "    - Select the jobs of data related, and keep the data scientists' record for analysis.\n",
    "    - Remove the duplicated records.\n",
    "    - Convert job description in HTML to text.\n",
    "    - Store the cleaned data into main table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c92f1c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T05:52:38.354706Z",
     "start_time": "2022-05-12T03:35:31.302460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The processed data exist, do you want to reload it?(y/n)y\n",
      "Shape of source file: (165290, 163)\n",
      "Shape of jobs related to data: (7347, 10)\n"
     ]
    }
   ],
   "source": [
    "outputfile= './01_data/output/datajobs.csv'\n",
    "datafile='./01_data/input/glassdoor/glassdoor.csv'\n",
    "\n",
    "if os.path.exists(datafile):\n",
    "    if os.path.exists(outputfile):\n",
    "        Reload=input(\"The processed data exist, do you want to reload it?(y/n)\")\n",
    "    else:\n",
    "        Reload='y'\n",
    "        \n",
    "    # reload the data file, and re-produce the csv of data scientist\n",
    "    if Reload.lower()=='y':\n",
    "        try:\n",
    "            glassdoor=pd.read_csv(datafile)\n",
    "            print(\"Shape of source file:\", glassdoor.shape)\n",
    "             # Produce the list of jobs related to data\n",
    "            # Only keep the non-duplicated records by employer names and jobs.\n",
    "            # Only keep the first records if there are duplicated. Here I keep the latest one\n",
    "            # Sort the jobs by posted date ascendingly\n",
    "            data_jobs=glassdoor[glassdoor['header.jobTitle'].str.contains(' data ',case=False)].sort_values(\n",
    "                by='header.posted',ascending=False).loc[:,[\n",
    "                'gaTrackerData.industry',\n",
    "                'header.employerName',\n",
    "                'gaTrackerData.jobTitle',\n",
    "                'job.jobReqId.long',\n",
    "                'job.description',\n",
    "                'header.posted',\n",
    "                'map.country',\n",
    "                'map.lat',\n",
    "                'map.lng',\n",
    "                'map.location']]\n",
    "            # Keep the first record if the duplicated exist.\n",
    "            data_jobs['duplicated']=data_jobs.duplicated()\n",
    "            data_jobs_unique=data_jobs[data_jobs['duplicated']==False].loc[:,[\n",
    "                'gaTrackerData.industry',\n",
    "                'header.employerName',\n",
    "                'gaTrackerData.jobTitle',\n",
    "                'job.jobReqId.long',\n",
    "                'job.description',\n",
    "                'header.posted',\n",
    "                'map.country',\n",
    "                'map.lat',\n",
    "                'map.lng',\n",
    "                'map.location']]\n",
    "            data_jobs_unique.to_csv('./01_Data/Output/datajobs.csv')\n",
    "            print(\"Shape of jobs related to data:\", data_jobs_unique.shape)\n",
    "            # Assign id into each posted position for the coming identification\n",
    "            # Remove all html tag, and convert each requirements into one item for every posted position.\n",
    "            jobs = pd.DataFrame(\n",
    "                columns=[\n",
    "                    'posting_date',\n",
    "                    'description',\n",
    "                    'title',\n",
    "                    'country',\n",
    "                    'employer',\n",
    "                    'industry',\n",
    "                    'id',\n",
    "                    'source',\n",
    "                    'lat',\n",
    "                    'lng',\n",
    "                    'location']\n",
    "            )\n",
    "            #for i in tqdm(range(len(data_jobs_unique))):\n",
    "            \n",
    "            for i in range(len(data_jobs_unique)):\n",
    "                \n",
    "                html_page=data_jobs_unique.iloc[i,4]\n",
    "                soup = BeautifulSoup(html_page, 'html.parser')\n",
    "                jobs_list = soup.find_all(\"li\")\n",
    "                job_text=''\n",
    "                for job in jobs_list:\n",
    "                    try:\n",
    "                        lang = detect(str(job.contents[0]))\n",
    "                    except:\n",
    "                        lang = \"error\"\n",
    "                # Only handle the position described in English \n",
    "                # since this program is solely focusing on English \n",
    "                    if lang=='en':\n",
    "                        job_text=job_text + str(job.contents[0]).lower().split(\"\\r\\n\")[0]+'.'\n",
    " \n",
    "                # Create df to store the converted job description in text format.\n",
    "                if job_text!='':\n",
    "                    \n",
    "                    jobs=jobs.append(\n",
    "                        {\n",
    "                            \"posting_date\":data_jobs_unique.iloc[i,5],\n",
    "                            \"description\":job_text,\n",
    "                            \"title\":data_jobs_unique.iloc[i,2],\n",
    "                            \"country\":data_jobs_unique.iloc[i,6],\n",
    "                            \"employer\":data_jobs_unique.iloc[i,1],\n",
    "                            \"industry\":data_jobs_unique.iloc[i,0],\n",
    "                            \"id\":data_jobs_unique.iloc[i,3],\n",
    "                            \"source\":\"Glassdoor\",\n",
    "                            \"lat\":data_jobs_unique.iloc[i,7],\n",
    "                            \"lng\":data_jobs_unique.iloc[i,8],\n",
    "                            \"location\":data_jobs_unique.iloc[i,9]\n",
    "                        },\n",
    "                                      ignore_index=True) \n",
    "            # Prevent the issue of 'utf-8' encoding.    \n",
    "            jobs['description'] = jobs['description'].apply(lambda x: \n",
    "                                                            x.encode('ascii', 'ignore').decode('ascii'))\n",
    "            jobs.to_csv(outputfile)\n",
    "        except Exception as e:\n",
    "            print(\"Failed to read the data file due to error:%s, please check the file or path!\" %e)\n",
    "    else:\n",
    "        jobs=pd.read_csv(outputfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a011b813",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T05:52:38.449652Z",
     "start_time": "2022-05-12T05:52:38.358595Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>posting_date</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>country</th>\n",
       "      <th>employer</th>\n",
       "      <th>industry</th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sep 5, 2019</td>\n",
       "      <td>interesse an innovativen technologie-themen.</td>\n",
       "      <td>Young Professional Consultant (w/m/d) Analytics / Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Camelot ITLab GmbH</td>\n",
       "      <td>Consulting</td>\n",
       "      <td>4.148184e+09</td>\n",
       "      <td>Glassdoor</td>\n",
       "      <td>50.9381</td>\n",
       "      <td>6.9571</td>\n",
       "      <td>Cologne</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sep 5, 2019</td>\n",
       "      <td>interesse an innovativen technologie-themen.</td>\n",
       "      <td>Young Professional Consultant (w/m/d) Analytics / Data Scientist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Camelot ITLab GmbH</td>\n",
       "      <td>Consulting</td>\n",
       "      <td>4.148184e+09</td>\n",
       "      <td>Glassdoor</td>\n",
       "      <td>49.4878</td>\n",
       "      <td>8.4663</td>\n",
       "      <td>Mannheim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sep 27, 2019</td>\n",
       "      <td>*artificial intelligence/ machine learning data scientist**.*main duties and responsibilities of the job**.investigating the stateoftheart methods in nlp, machine learning and ai.applying nlp meth...</td>\n",
       "      <td>AI/ML Data Scientist</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Tec Partners</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.203393e+09</td>\n",
       "      <td>Glassdoor</td>\n",
       "      <td>51.4833</td>\n",
       "      <td>-0.1167</td>\n",
       "      <td>Charing Cross, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sep 23, 2019</td>\n",
       "      <td>demonstrable handson experience in deploying and maintaining machine learning models in production environments.familiar with offline (batch) and online (live/stream) data pipelines.advanced pytho...</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Wade Macdonald</td>\n",
       "      <td>Staffing &amp; Outsourcing</td>\n",
       "      <td>4.202983e+09</td>\n",
       "      <td>Glassdoor</td>\n",
       "      <td>51.4333</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>Reading, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sep 19, 2019</td>\n",
       "      <td>performing fundamental research work on applying deep learning to different types of data (categorical, temporal, etc.)..constructing data pipelines and applying data processing, cleansing and int...</td>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Giatec</td>\n",
       "      <td>Electrical &amp; Electronic Manufacturing</td>\n",
       "      <td>4.136718e+09</td>\n",
       "      <td>Glassdoor</td>\n",
       "      <td>45.4167</td>\n",
       "      <td>-75.7000</td>\n",
       "      <td>Ottawa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3308</th>\n",
       "      <td>Jul 11, 2019</td>\n",
       "      <td>challenging and exciting projects for renowned clients.possibility to develop internationally in cooperation with our offices in cologne and paris.office location in the centre of paris.strong tea...</td>\n",
       "      <td>INTERN - Data Scientist (m/w/d)</td>\n",
       "      <td>FR</td>\n",
       "      <td>respondi sarl</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.121410e+09</td>\n",
       "      <td>Glassdoor</td>\n",
       "      <td>48.8667</td>\n",
       "      <td>2.3333</td>\n",
       "      <td>Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3313</th>\n",
       "      <td>Aug 9, 2019</td>\n",
       "      <td>ms/bs in cs/ee, mathematical or machine learning related disciplines, with 10 or more years of experience.solid understanding ofprobability, statistics, machine learning, data science.a/b testing ...</td>\n",
       "      <td>Principal Applied Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Computer Hardware &amp; Software</td>\n",
       "      <td>4.080983e+09</td>\n",
       "      <td>Glassdoor</td>\n",
       "      <td>12.9670</td>\n",
       "      <td>77.5873</td>\n",
       "      <td>Bangalore, Karnataka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3314</th>\n",
       "      <td>Aug 9, 2019</td>\n",
       "      <td>ms/bs in cs/ee, mathematical or machine learning related disciplines, with 10 or more years of experience.experience leading a team of applied data scientists.solid understanding ofprobability, st...</td>\n",
       "      <td>Principal Applied Data Scientist Manager</td>\n",
       "      <td>India</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Computer Hardware &amp; Software</td>\n",
       "      <td>4.080983e+09</td>\n",
       "      <td>Glassdoor</td>\n",
       "      <td>12.9670</td>\n",
       "      <td>77.5873</td>\n",
       "      <td>Bangalore, Karnataka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3328</th>\n",
       "      <td>Aug 23, 2019</td>\n",
       "      <td>agiler workflow.</td>\n",
       "      <td>Mitarbeiter Data Scientist (w/m/d)</td>\n",
       "      <td>DE</td>\n",
       "      <td>eClever Entwicklungs OHG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.146647e+09</td>\n",
       "      <td>Glassdoor</td>\n",
       "      <td>51.0517</td>\n",
       "      <td>13.7369</td>\n",
       "      <td>Dresden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3329</th>\n",
       "      <td>Aug 21, 2019</td>\n",
       "      <td>machine learning et deep learning.plateformes de recherche d'information : elasticsearch, solr.</td>\n",
       "      <td>Stage : Assistant Data Scientist - Moteur de recherche sémantique H/F</td>\n",
       "      <td>France</td>\n",
       "      <td>Crédit Agricole</td>\n",
       "      <td>Investment Banking &amp; Asset Management</td>\n",
       "      <td>4.189587e+09</td>\n",
       "      <td>Glassdoor</td>\n",
       "      <td>48.8167</td>\n",
       "      <td>2.3167</td>\n",
       "      <td>Montrouge</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>784 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      posting_date  \\\n",
       "2      Sep 5, 2019   \n",
       "3      Sep 5, 2019   \n",
       "6     Sep 27, 2019   \n",
       "13    Sep 23, 2019   \n",
       "18    Sep 19, 2019   \n",
       "...            ...   \n",
       "3308  Jul 11, 2019   \n",
       "3313   Aug 9, 2019   \n",
       "3314   Aug 9, 2019   \n",
       "3328  Aug 23, 2019   \n",
       "3329  Aug 21, 2019   \n",
       "\n",
       "                                                                                                                                                                                                  description  \\\n",
       "2                                                                                                                                                                interesse an innovativen technologie-themen.   \n",
       "3                                                                                                                                                                interesse an innovativen technologie-themen.   \n",
       "6     *artificial intelligence/ machine learning data scientist**.*main duties and responsibilities of the job**.investigating the stateoftheart methods in nlp, machine learning and ai.applying nlp meth...   \n",
       "13    demonstrable handson experience in deploying and maintaining machine learning models in production environments.familiar with offline (batch) and online (live/stream) data pipelines.advanced pytho...   \n",
       "18    performing fundamental research work on applying deep learning to different types of data (categorical, temporal, etc.)..constructing data pipelines and applying data processing, cleansing and int...   \n",
       "...                                                                                                                                                                                                       ...   \n",
       "3308  challenging and exciting projects for renowned clients.possibility to develop internationally in cooperation with our offices in cologne and paris.office location in the centre of paris.strong tea...   \n",
       "3313  ms/bs in cs/ee, mathematical or machine learning related disciplines, with 10 or more years of experience.solid understanding ofprobability, statistics, machine learning, data science.a/b testing ...   \n",
       "3314  ms/bs in cs/ee, mathematical or machine learning related disciplines, with 10 or more years of experience.experience leading a team of applied data scientists.solid understanding ofprobability, st...   \n",
       "3328                                                                                                                                                                                         agiler workflow.   \n",
       "3329                                                                                                          machine learning et deep learning.plateformes de recherche d'information : elasticsearch, solr.   \n",
       "\n",
       "                                                                      title  \\\n",
       "2          Young Professional Consultant (w/m/d) Analytics / Data Scientist   \n",
       "3          Young Professional Consultant (w/m/d) Analytics / Data Scientist   \n",
       "6                                                      AI/ML Data Scientist   \n",
       "13                                                    Senior Data Scientist   \n",
       "18                                                    Junior Data Scientist   \n",
       "...                                                                     ...   \n",
       "3308                                        INTERN - Data Scientist (m/w/d)   \n",
       "3313                                       Principal Applied Data Scientist   \n",
       "3314                               Principal Applied Data Scientist Manager   \n",
       "3328                                     Mitarbeiter Data Scientist (w/m/d)   \n",
       "3329  Stage : Assistant Data Scientist - Moteur de recherche sémantique H/F   \n",
       "\n",
       "             country                  employer  \\\n",
       "2                NaN        Camelot ITLab GmbH   \n",
       "3                NaN        Camelot ITLab GmbH   \n",
       "6     United Kingdom              Tec Partners   \n",
       "13    United Kingdom            Wade Macdonald   \n",
       "18            Canada                    Giatec   \n",
       "...              ...                       ...   \n",
       "3308              FR             respondi sarl   \n",
       "3313           India                 Microsoft   \n",
       "3314           India                 Microsoft   \n",
       "3328              DE  eClever Entwicklungs OHG   \n",
       "3329          France           Crédit Agricole   \n",
       "\n",
       "                                   industry            id     source      lat  \\\n",
       "2                                Consulting  4.148184e+09  Glassdoor  50.9381   \n",
       "3                                Consulting  4.148184e+09  Glassdoor  49.4878   \n",
       "6                                       NaN  4.203393e+09  Glassdoor  51.4833   \n",
       "13                   Staffing & Outsourcing  4.202983e+09  Glassdoor  51.4333   \n",
       "18    Electrical & Electronic Manufacturing  4.136718e+09  Glassdoor  45.4167   \n",
       "...                                     ...           ...        ...      ...   \n",
       "3308                                    NaN  4.121410e+09  Glassdoor  48.8667   \n",
       "3313           Computer Hardware & Software  4.080983e+09  Glassdoor  12.9670   \n",
       "3314           Computer Hardware & Software  4.080983e+09  Glassdoor  12.9670   \n",
       "3328                                    NaN  4.146647e+09  Glassdoor  51.0517   \n",
       "3329  Investment Banking & Asset Management  4.189587e+09  Glassdoor  48.8167   \n",
       "\n",
       "          lng                location  \n",
       "2      6.9571                 Cologne  \n",
       "3      8.4663                Mannheim  \n",
       "6     -0.1167  Charing Cross, England  \n",
       "13    -1.0000        Reading, England  \n",
       "18   -75.7000                  Ottawa  \n",
       "...       ...                     ...  \n",
       "3308   2.3333                   Paris  \n",
       "3313  77.5873    Bangalore, Karnataka  \n",
       "3314  77.5873    Bangalore, Karnataka  \n",
       "3328  13.7369                 Dresden  \n",
       "3329   2.3167               Montrouge  \n",
       "\n",
       "[784 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select data scientist jobs\n",
    "df_main=jobs[jobs['title'].str.contains(r'^(?=.*data)(?=.*scientist)',case=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d9cde7",
   "metadata": {},
   "source": [
    "### Fill / Standardize the country names\n",
    "\n",
    "- Those job postings without countries can find out countries by:\n",
    "    - From the job posting who has the same locations, but the country is NOT empty.\n",
    "    - Based on Location to look for the country names.\n",
    "\n",
    "- The short names of countries will be converted to full names based on the mapping of glassdoor's table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c778630",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T05:52:38.506399Z",
     "start_time": "2022-05-12T05:52:38.461690Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify how many jobs'country are empty\n",
    "len(df_main[df_main['country'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df808503",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T05:52:38.543447Z",
     "start_time": "2022-05-12T05:52:38.511191Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the mapping table for those which has country names and locations\n",
    "a_city=df_main[df_main['country'].isnull()==False]\\\n",
    "    [['country','location']].apply(lambda x: (x.iloc[0],x.iloc[1]),axis=1).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca60af24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T05:52:38.572885Z",
     "start_time": "2022-05-12T05:52:38.564456Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create replacing functions to \n",
    "# 1) return 1st element if 2nd element in array is equal to target string\n",
    "# 2) Return empty if target string could be not found\n",
    "def map_replace(a_source=[],s_target=''):\n",
    "    for item in a_source:\n",
    "        if str(item[1]).strip().lower()==s_target.strip().lower():\n",
    "            return item[0]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f8c39e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T05:52:38.701133Z",
     "start_time": "2022-05-12T05:52:38.580322Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fill the country names\n",
    "df_main['country']=df_main.apply(lambda \n",
    "                                 x: map_replace(a_city,x.iloc[10]) if pd.isna(x.iloc[3]) else x.iloc[3],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f65f5b80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T05:52:38.727933Z",
     "start_time": "2022-05-12T05:52:38.706701Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many postings without country names still are left\n",
    "len(df_main[df_main['country'].isnull()==True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1d5ed6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T05:52:38.853138Z",
     "start_time": "2022-05-12T05:52:38.763792Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import country mapping table for short names' conversion\n",
    "countryfile='./01_data/input/glassdoor/country_names_2_digit_codes.csv'\n",
    "df_country=pd.read_csv(countryfile)\n",
    "\n",
    "# Create function to get and standardize the country name\n",
    "def get_country(country='',lat='0',lng='0',city=''):\n",
    "    try:\n",
    "        country_name=''\n",
    "        \n",
    "        # country name's shortname to full name\n",
    "        if len(country)<=3 and len(country)>1:\n",
    "            country_name=df_country[df_country['Code'].str.lower()==country.lower()]['Name']\n",
    "            \n",
    "            if not country_name.empty:\n",
    "                \n",
    "                return country_name\n",
    "            \n",
    "        else:\n",
    "        # if country name does not exist, look for country name by geo location (latitude, longitude)\n",
    "            if country=='':\n",
    "                if (lat!='0' and lng!='0'):\n",
    "                    # initialize Nominatim API \n",
    "\n",
    "                    geolocator = Nominatim(user_agent=\"geoapiExercises\")\n",
    "\n",
    "                    # Latitude & Longitude input\n",
    "\n",
    "                    location = geolocator.reverse(lat+\",\"+lng,language='en')\n",
    "                    country_name = location.raw['address'].get('country', '')\n",
    "                    if country_name !='':\n",
    "                        return country_name\n",
    "        # if no geo location, search for country name by city name\n",
    "                else:\n",
    "                    if city !='':\n",
    "                        geolocator = Nominatim(timeout=10,user_agent=\"geoapiExercises\")\n",
    "                        #print(city)\n",
    "                        location = geolocator.geocode(city,language='en')\n",
    "                        loc_dict = location.raw\n",
    "                        #print(loc_dict)\n",
    "                        if loc_dict is not None:\n",
    "                            if ',' in loc_dict['display_name']:\n",
    "                                country_name=loc_dict['display_name'].rsplit(',' , 1)[1]\n",
    "                            else:\n",
    "                                country_name=loc_dict['display_name']\n",
    "                            return country_name\n",
    "            else:\n",
    "                return country\n",
    "                    \n",
    "    except Exception as e:\n",
    "            print(\"error:%s\" %e)\n",
    "            print(lat,lng,city,loc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b7c6e8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T05:55:57.005476Z",
     "start_time": "2022-05-12T05:52:38.878630Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fill the country names based on locations.\n",
    "df_main['country']=df_main.apply(lambda x: get_country(city=x.iloc[10])\n",
    "                                 if pd.isna(x.iloc[3]) else x.iloc[3],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a645d703",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T05:55:57.015279Z",
     "start_time": "2022-05-12T05:55:57.007940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check how many postings without country name are left.\n",
    "len(df_main[df_main['country'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "935c34d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T05:55:57.049539Z",
     "start_time": "2022-05-12T05:55:57.019344Z"
    }
   },
   "outputs": [],
   "source": [
    "# Add 2 Codes for USA and UK given previous mapping table is lack of them\n",
    "df_temp=pd.DataFrame({'Name':['United Kingdom','United States','Switzerland'],\n",
    "                      'Code':['UK','USA','CHE']},columns=['Name','Code']\n",
    "                              )\n",
    "df_country=df_country.append(df_temp,ignore_index=True)\n",
    "\n",
    "# Create mapping array for short names to full names\n",
    "a_name=df_country[['Name','Code']].apply(lambda x: (x.iloc[0],x.iloc[1]),axis=1).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39247953",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T05:55:57.107327Z",
     "start_time": "2022-05-12T05:55:57.097486Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "382"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display numbers of records which has the short names of country\n",
    "len(df_main[(df_main['country'].str.len()<=3) & (df_main['country'].str.len()>=2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8f2487e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T05:55:57.367682Z",
     "start_time": "2022-05-12T05:55:57.112245Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert short name of country to full name\n",
    "df_main['country']=df_main.apply(lambda x: map_replace(a_name,x.iloc[3]) \n",
    "                                 if (pd.isna(map_replace(a_name,x.iloc[3]))==False) else x.iloc[3],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61f7c3ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T09:04:51.898127Z",
     "start_time": "2022-05-12T09:04:51.848989Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify what the short names are if these exist.\n",
    "len(df_main[df_main['country'].str.len()<=3][['country','location']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e8aac6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T05:55:58.453883Z",
     "start_time": "2022-05-12T05:55:57.662721Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing shutdown due to inactivity...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 14:56:00,915 - INFO     - Executing shutdown due to inactivity...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing shutdown...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 14:56:01,071 - INFO     - Executing shutdown...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception on /shutdown [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gangli/Library/Python/3.7/lib/python/site-packages/flask/app.py\", line 2077, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/Users/gangli/Library/Python/3.7/lib/python/site-packages/flask/app.py\", line 1525, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/Users/gangli/Library/Python/3.7/lib/python/site-packages/flask/app.py\", line 1523, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/Users/gangli/Library/Python/3.7/lib/python/site-packages/flask/app.py\", line 1509, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dtale/app.py\", line 410, in shutdown\n",
      "    shutdown_server()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dtale/app.py\", line 396, in shutdown_server\n",
      "    raise RuntimeError(\"Not running with the Werkzeug Server\")\n",
      "RuntimeError: Not running with the Werkzeug Server\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 14:56:01,073 - ERROR    - Exception on /shutdown [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/gangli/Library/Python/3.7/lib/python/site-packages/flask/app.py\", line 2077, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/Users/gangli/Library/Python/3.7/lib/python/site-packages/flask/app.py\", line 1525, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/Users/gangli/Library/Python/3.7/lib/python/site-packages/flask/app.py\", line 1523, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/Users/gangli/Library/Python/3.7/lib/python/site-packages/flask/app.py\", line 1509, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dtale/app.py\", line 410, in shutdown\n",
      "    shutdown_server()\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/dtale/app.py\", line 396, in shutdown_server\n",
      "    raise RuntimeError(\"Not running with the Werkzeug Server\")\n",
      "RuntimeError: Not running with the Werkzeug Server\n"
     ]
    }
   ],
   "source": [
    "# Export main table only including the jobs of data scientists\n",
    "ds_file= './01_data/output/datascientists.csv'\n",
    "df_main.to_csv(ds_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f4c497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform EDA to check main table\n",
    "d1 = dtale.show(df_main)\n",
    "d1.open_browser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eed8043",
   "metadata": {},
   "source": [
    "### Fill / Standardize the industry name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd64ba7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T09:07:46.336231Z",
     "start_time": "2022-05-12T09:07:46.311149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify how many jobs'industry names are empty\n",
    "len(df_main[df_main['industry'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8dc53fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T09:11:00.834918Z",
     "start_time": "2022-05-12T09:11:00.789023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify whether the industry names could be found from those job postings with industry name and same employer\n",
    "len(set(df_main[df_main['industry'].isnull()==False]['employer']) &\\\n",
    "                set(df_main[df_main['industry'].isnull()]['employer']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0039d12e",
   "metadata": {},
   "source": [
    "#### To be found way to fill the missing industry names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff36181",
   "metadata": {},
   "source": [
    "## Extract skills from job desription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0549dd71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T09:45:52.214522Z",
     "start_time": "2022-05-12T09:45:52.167496Z"
    }
   },
   "outputs": [],
   "source": [
    "default_stemmer = PorterStemmer()\n",
    "default_stopwords = stopwords.words('english') # or any other list of your choice\n",
    "def clean_text(text, ):\n",
    "\n",
    "    def tokenize_text(text):\n",
    "        return [w for s in sent_tokenize(text) for w in word_tokenize(s)]\n",
    "\n",
    "    def remove_special_characters(text, characters=string.punctuation.replace('-', '')):\n",
    "        tokens = tokenize_text(text)\n",
    "        pattern = re.compile('[{}]'.format(re.escape(characters)))\n",
    "        return ' '.join(filter(None, [pattern.sub('', t) for t in tokens]))\n",
    "\n",
    "    def stem_text(text, stemmer=default_stemmer):\n",
    "        tokens = tokenize_text(text)\n",
    "        return ' '.join([stemmer.stem(t) for t in tokens])\n",
    "\n",
    "    def remove_stopwords(text, stop_words=default_stopwords):\n",
    "        tokens = [w for w in tokenize_text(text) if w not in stop_words]\n",
    "        return ' '.join(tokens)\n",
    "\n",
    "    text = text.strip(' ') # strip whitespaces\n",
    "    text = text.lower() # lowercase\n",
    "    #text = stem_text(text) # stemming\n",
    "    text = remove_special_characters(text) # remove punctuation and symbols\n",
    "    text = remove_stopwords(text) # remove stopwords\n",
    "    #text.strip(' ') # strip whitespaces again?\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2a9e2ec0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T09:45:57.548048Z",
     "start_time": "2022-05-12T09:45:55.107975Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create column \"description_cln\" to store the result of text cleaning\n",
    "df_main['description_cln']=df_main['description'].apply(lambda x: clean_text(x, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "32fa5f55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T09:45:58.937742Z",
     "start_time": "2022-05-12T09:45:58.927644Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'artificial intelligence machine learning data scientist main duties responsibilities job investigating stateoftheart methods nlp machine learning aiapplying nlp methods extract insights text email messagesapplying supervised semisupervised machine learning approaches classification large scale datasets cybersecurity domain developing bespoke interactive visualisation tool enable endusers interact machine learning component skills qualifications experience needed 3 years experience visual analytics machine learning data visualisation nlp data scienceexpertise natural language processing visualisationsupported active learningminimum 3 years research machine learning information visualisationproven industry experience machine learning information visualisationproficient pythonexperience research development large scale projects related cybersecurityexperience using machine learning libraries nlp big data spacy gensim nltk sparkml experience developing bespoke interactive data visualisation tools using d3js reactproven track record publications top journals conferences including tvcg icmlcompetitive dependant experience10 performancebased bonus scheme'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main['description_cln'].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "202a9477",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T09:39:10.823387Z",
     "start_time": "2022-05-12T09:39:09.106669Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 17:39:09,154 - INFO     - Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling DetectKeyPhrases\n",
      "End of DetectKeyPhrases\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comprehend = boto3.client(service_name='comprehend', region_name='us-east-2')\n",
    "                \n",
    "#text = \"It is raining today in Seattle\"\n",
    "\n",
    "print('Calling DetectKeyPhrases')\n",
    "#df=pd.DataFrame()\n",
    "df_list=[]\n",
    "i=2\n",
    "if i==2:\n",
    "    if len(df_main[\"description\"].iloc[i])<=5000: #AWS' limitation on one request\n",
    "        dump_json=json.dumps(comprehend.detect_key_phrases(Text=df_main[\"description\"].iloc[i]\n",
    "                                                       , LanguageCode='en'), sort_keys=True, indent=4)\n",
    "        df_phrases=pd.json_normalize(json.loads(dump_json)['KeyPhrases'])\n",
    "        df_phrases['id']=df_main[\"id\"].iloc[i]\n",
    "        df_list.append(df_phrases)\n",
    "\n",
    "    else:\n",
    "        None # to be handled\n",
    "        \n",
    "df=pd.concat(df_list)\n",
    "print('End of DetectKeyPhrases\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ffb4c578",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T09:39:16.621297Z",
     "start_time": "2022-05-12T09:39:16.577565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BeginOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>0.803214</td>\n",
       "      <td>artificial intelligence/ machine</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43</td>\n",
       "      <td>57</td>\n",
       "      <td>0.802882</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61</td>\n",
       "      <td>93</td>\n",
       "      <td>0.994325</td>\n",
       "      <td>main duties and responsibilities</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97</td>\n",
       "      <td>104</td>\n",
       "      <td>0.999277</td>\n",
       "      <td>the job</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>121</td>\n",
       "      <td>146</td>\n",
       "      <td>0.987720</td>\n",
       "      <td>the stateoftheart methods</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>150</td>\n",
       "      <td>175</td>\n",
       "      <td>0.753794</td>\n",
       "      <td>nlp, machine learning and</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>188</td>\n",
       "      <td>199</td>\n",
       "      <td>0.879215</td>\n",
       "      <td>nlp methods</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>211</td>\n",
       "      <td>219</td>\n",
       "      <td>0.996371</td>\n",
       "      <td>insights</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>225</td>\n",
       "      <td>229</td>\n",
       "      <td>0.999825</td>\n",
       "      <td>text</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>238</td>\n",
       "      <td>261</td>\n",
       "      <td>0.916269</td>\n",
       "      <td>email messages.applying</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>262</td>\n",
       "      <td>299</td>\n",
       "      <td>0.766822</td>\n",
       "      <td>supervised and semisupervised machine</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>309</td>\n",
       "      <td>319</td>\n",
       "      <td>0.729605</td>\n",
       "      <td>approaches</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>323</td>\n",
       "      <td>337</td>\n",
       "      <td>0.999538</td>\n",
       "      <td>classification</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>341</td>\n",
       "      <td>361</td>\n",
       "      <td>0.999457</td>\n",
       "      <td>large scale datasets</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>365</td>\n",
       "      <td>385</td>\n",
       "      <td>0.997907</td>\n",
       "      <td>cybersecurity domain</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>387</td>\n",
       "      <td>397</td>\n",
       "      <td>0.579899</td>\n",
       "      <td>developing</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>398</td>\n",
       "      <td>436</td>\n",
       "      <td>0.902761</td>\n",
       "      <td>bespoke interactive visualisation tool</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>447</td>\n",
       "      <td>455</td>\n",
       "      <td>0.944046</td>\n",
       "      <td>endusers</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>473</td>\n",
       "      <td>484</td>\n",
       "      <td>0.998642</td>\n",
       "      <td>the machine</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>494</td>\n",
       "      <td>503</td>\n",
       "      <td>0.887898</td>\n",
       "      <td>component</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>505</td>\n",
       "      <td>542</td>\n",
       "      <td>0.929959</td>\n",
       "      <td>skills, qualifications and experience</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>551</td>\n",
       "      <td>560</td>\n",
       "      <td>0.725699</td>\n",
       "      <td>.3+ years</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>575</td>\n",
       "      <td>591</td>\n",
       "      <td>0.996283</td>\n",
       "      <td>visual analytics</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>593</td>\n",
       "      <td>609</td>\n",
       "      <td>0.963537</td>\n",
       "      <td>machine learning</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>611</td>\n",
       "      <td>660</td>\n",
       "      <td>0.839465</td>\n",
       "      <td>data visualisation, nlp or data science.expertise</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>664</td>\n",
       "      <td>691</td>\n",
       "      <td>0.990090</td>\n",
       "      <td>natural language processing</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>719</td>\n",
       "      <td>742</td>\n",
       "      <td>0.644296</td>\n",
       "      <td>active learning.minimum</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>743</td>\n",
       "      <td>750</td>\n",
       "      <td>0.908430</td>\n",
       "      <td>3 years</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>754</td>\n",
       "      <td>762</td>\n",
       "      <td>0.998409</td>\n",
       "      <td>research</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>766</td>\n",
       "      <td>839</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>machine learning and information visualisation.proven industry experience</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>843</td>\n",
       "      <td>900</td>\n",
       "      <td>0.778003</td>\n",
       "      <td>machine learning and information visualisation.proficient</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>904</td>\n",
       "      <td>921</td>\n",
       "      <td>0.951131</td>\n",
       "      <td>python.experience</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>925</td>\n",
       "      <td>949</td>\n",
       "      <td>0.998023</td>\n",
       "      <td>research and development</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>953</td>\n",
       "      <td>973</td>\n",
       "      <td>0.995761</td>\n",
       "      <td>large scale projects</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>985</td>\n",
       "      <td>1009</td>\n",
       "      <td>0.814167</td>\n",
       "      <td>cybersecurity.experience</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1016</td>\n",
       "      <td>1032</td>\n",
       "      <td>0.768928</td>\n",
       "      <td>machine learning</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1033</td>\n",
       "      <td>1042</td>\n",
       "      <td>0.937553</td>\n",
       "      <td>libraries</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1047</td>\n",
       "      <td>1063</td>\n",
       "      <td>0.925213</td>\n",
       "      <td>nlp and big data</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1065</td>\n",
       "      <td>1093</td>\n",
       "      <td>0.990107</td>\n",
       "      <td>spacy, gensim, nltk, sparkml</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1120</td>\n",
       "      <td>1164</td>\n",
       "      <td>0.943926</td>\n",
       "      <td>bespoke interactive data visualisation tools</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1171</td>\n",
       "      <td>1193</td>\n",
       "      <td>0.731064</td>\n",
       "      <td>d3.js and react.proven</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1194</td>\n",
       "      <td>1206</td>\n",
       "      <td>0.733483</td>\n",
       "      <td>track record</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1210</td>\n",
       "      <td>1222</td>\n",
       "      <td>0.997862</td>\n",
       "      <td>publications</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>1226</td>\n",
       "      <td>1254</td>\n",
       "      <td>0.991048</td>\n",
       "      <td>top journals and conferences</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1265</td>\n",
       "      <td>1269</td>\n",
       "      <td>0.888397</td>\n",
       "      <td>tvcg</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1308</td>\n",
       "      <td>1322</td>\n",
       "      <td>0.953806</td>\n",
       "      <td>experience.10%</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1340</td>\n",
       "      <td>1352</td>\n",
       "      <td>0.762774</td>\n",
       "      <td>bonus scheme</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    BeginOffset  EndOffset     Score  \\\n",
       "0             1         33  0.803214   \n",
       "1            43         57  0.802882   \n",
       "2            61         93  0.994325   \n",
       "3            97        104  0.999277   \n",
       "4           121        146  0.987720   \n",
       "5           150        175  0.753794   \n",
       "6           188        199  0.879215   \n",
       "7           211        219  0.996371   \n",
       "8           225        229  0.999825   \n",
       "9           238        261  0.916269   \n",
       "10          262        299  0.766822   \n",
       "11          309        319  0.729605   \n",
       "12          323        337  0.999538   \n",
       "13          341        361  0.999457   \n",
       "14          365        385  0.997907   \n",
       "15          387        397  0.579899   \n",
       "16          398        436  0.902761   \n",
       "17          447        455  0.944046   \n",
       "18          473        484  0.998642   \n",
       "19          494        503  0.887898   \n",
       "20          505        542  0.929959   \n",
       "21          551        560  0.725699   \n",
       "22          575        591  0.996283   \n",
       "23          593        609  0.963537   \n",
       "24          611        660  0.839465   \n",
       "25          664        691  0.990090   \n",
       "26          719        742  0.644296   \n",
       "27          743        750  0.908430   \n",
       "28          754        762  0.998409   \n",
       "29          766        839  0.806452   \n",
       "30          843        900  0.778003   \n",
       "31          904        921  0.951131   \n",
       "32          925        949  0.998023   \n",
       "33          953        973  0.995761   \n",
       "34          985       1009  0.814167   \n",
       "35         1016       1032  0.768928   \n",
       "36         1033       1042  0.937553   \n",
       "37         1047       1063  0.925213   \n",
       "38         1065       1093  0.990107   \n",
       "39         1120       1164  0.943926   \n",
       "40         1171       1193  0.731064   \n",
       "41         1194       1206  0.733483   \n",
       "42         1210       1222  0.997862   \n",
       "43         1226       1254  0.991048   \n",
       "44         1265       1269  0.888397   \n",
       "45         1308       1322  0.953806   \n",
       "46         1340       1352  0.762774   \n",
       "\n",
       "                                                                         Text  \\\n",
       "0                                            artificial intelligence/ machine   \n",
       "1                                                              data scientist   \n",
       "2                                            main duties and responsibilities   \n",
       "3                                                                     the job   \n",
       "4                                                   the stateoftheart methods   \n",
       "5                                                   nlp, machine learning and   \n",
       "6                                                                 nlp methods   \n",
       "7                                                                    insights   \n",
       "8                                                                        text   \n",
       "9                                                     email messages.applying   \n",
       "10                                      supervised and semisupervised machine   \n",
       "11                                                                 approaches   \n",
       "12                                                             classification   \n",
       "13                                                       large scale datasets   \n",
       "14                                                       cybersecurity domain   \n",
       "15                                                                 developing   \n",
       "16                                     bespoke interactive visualisation tool   \n",
       "17                                                                   endusers   \n",
       "18                                                                the machine   \n",
       "19                                                                  component   \n",
       "20                                      skills, qualifications and experience   \n",
       "21                                                                  .3+ years   \n",
       "22                                                           visual analytics   \n",
       "23                                                           machine learning   \n",
       "24                          data visualisation, nlp or data science.expertise   \n",
       "25                                                natural language processing   \n",
       "26                                                    active learning.minimum   \n",
       "27                                                                    3 years   \n",
       "28                                                                   research   \n",
       "29  machine learning and information visualisation.proven industry experience   \n",
       "30                  machine learning and information visualisation.proficient   \n",
       "31                                                          python.experience   \n",
       "32                                                   research and development   \n",
       "33                                                       large scale projects   \n",
       "34                                                   cybersecurity.experience   \n",
       "35                                                           machine learning   \n",
       "36                                                                  libraries   \n",
       "37                                                           nlp and big data   \n",
       "38                                               spacy, gensim, nltk, sparkml   \n",
       "39                               bespoke interactive data visualisation tools   \n",
       "40                                                     d3.js and react.proven   \n",
       "41                                                               track record   \n",
       "42                                                               publications   \n",
       "43                                               top journals and conferences   \n",
       "44                                                                       tvcg   \n",
       "45                                                             experience.10%   \n",
       "46                                                               bonus scheme   \n",
       "\n",
       "              id  \n",
       "0   4.203393e+09  \n",
       "1   4.203393e+09  \n",
       "2   4.203393e+09  \n",
       "3   4.203393e+09  \n",
       "4   4.203393e+09  \n",
       "5   4.203393e+09  \n",
       "6   4.203393e+09  \n",
       "7   4.203393e+09  \n",
       "8   4.203393e+09  \n",
       "9   4.203393e+09  \n",
       "10  4.203393e+09  \n",
       "11  4.203393e+09  \n",
       "12  4.203393e+09  \n",
       "13  4.203393e+09  \n",
       "14  4.203393e+09  \n",
       "15  4.203393e+09  \n",
       "16  4.203393e+09  \n",
       "17  4.203393e+09  \n",
       "18  4.203393e+09  \n",
       "19  4.203393e+09  \n",
       "20  4.203393e+09  \n",
       "21  4.203393e+09  \n",
       "22  4.203393e+09  \n",
       "23  4.203393e+09  \n",
       "24  4.203393e+09  \n",
       "25  4.203393e+09  \n",
       "26  4.203393e+09  \n",
       "27  4.203393e+09  \n",
       "28  4.203393e+09  \n",
       "29  4.203393e+09  \n",
       "30  4.203393e+09  \n",
       "31  4.203393e+09  \n",
       "32  4.203393e+09  \n",
       "33  4.203393e+09  \n",
       "34  4.203393e+09  \n",
       "35  4.203393e+09  \n",
       "36  4.203393e+09  \n",
       "37  4.203393e+09  \n",
       "38  4.203393e+09  \n",
       "39  4.203393e+09  \n",
       "40  4.203393e+09  \n",
       "41  4.203393e+09  \n",
       "42  4.203393e+09  \n",
       "43  4.203393e+09  \n",
       "44  4.203393e+09  \n",
       "45  4.203393e+09  \n",
       "46  4.203393e+09  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb282a28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T09:46:24.528863Z",
     "start_time": "2022-05-12T09:46:23.330412Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling DetectKeyPhrases\n",
      "End of DetectKeyPhrases\n",
      "\n"
     ]
    }
   ],
   "source": [
    "comprehend = boto3.client(service_name='comprehend', region_name='us-east-2')\n",
    "                \n",
    "#text = \"It is raining today in Seattle\"\n",
    "\n",
    "print('Calling DetectKeyPhrases')\n",
    "#df=pd.DataFrame()\n",
    "df_list=[]\n",
    "i=2\n",
    "if i==2:\n",
    "    if len(df_main[\"description_cln\"].iloc[i])<=5000: #AWS' limitation on one request\n",
    "        dump_json=json.dumps(comprehend.detect_key_phrases(Text=df_main[\"description_cln\"].iloc[i]\n",
    "                                                       , LanguageCode='en'), sort_keys=True, indent=4)\n",
    "        df_phrases=pd.json_normalize(json.loads(dump_json)['KeyPhrases'])\n",
    "        df_phrases['id']=df_main[\"id\"].iloc[i]\n",
    "        df_list.append(df_phrases)\n",
    "\n",
    "    else:\n",
    "        None # to be handled\n",
    "        \n",
    "df_cln=pd.concat(df_list)\n",
    "print('End of DetectKeyPhrases\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bed8a5fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T09:46:24.644796Z",
     "start_time": "2022-05-12T09:46:24.607565Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BeginOffset</th>\n",
       "      <th>EndOffset</th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.871532</td>\n",
       "      <td>artificial intelligence machine</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>55</td>\n",
       "      <td>0.847129</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56</td>\n",
       "      <td>88</td>\n",
       "      <td>0.814921</td>\n",
       "      <td>main duties responsibilities job</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103</td>\n",
       "      <td>124</td>\n",
       "      <td>0.996263</td>\n",
       "      <td>stateoftheart methods</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125</td>\n",
       "      <td>136</td>\n",
       "      <td>0.555494</td>\n",
       "      <td>nlp machine</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>146</td>\n",
       "      <td>168</td>\n",
       "      <td>0.885270</td>\n",
       "      <td>aiapplying nlp methods</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>177</td>\n",
       "      <td>185</td>\n",
       "      <td>0.955149</td>\n",
       "      <td>insights</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>186</td>\n",
       "      <td>213</td>\n",
       "      <td>0.814103</td>\n",
       "      <td>text email messagesapplying</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>214</td>\n",
       "      <td>247</td>\n",
       "      <td>0.648581</td>\n",
       "      <td>supervised semisupervised machine</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>257</td>\n",
       "      <td>267</td>\n",
       "      <td>0.484630</td>\n",
       "      <td>approaches</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>268</td>\n",
       "      <td>303</td>\n",
       "      <td>0.803846</td>\n",
       "      <td>classification large scale datasets</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>304</td>\n",
       "      <td>324</td>\n",
       "      <td>0.757898</td>\n",
       "      <td>cybersecurity domain</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>336</td>\n",
       "      <td>374</td>\n",
       "      <td>0.976523</td>\n",
       "      <td>bespoke interactive visualisation tool</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>382</td>\n",
       "      <td>390</td>\n",
       "      <td>0.975490</td>\n",
       "      <td>endusers</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>400</td>\n",
       "      <td>407</td>\n",
       "      <td>0.958755</td>\n",
       "      <td>machine</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>417</td>\n",
       "      <td>459</td>\n",
       "      <td>0.735959</td>\n",
       "      <td>component skills qualifications experience</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>467</td>\n",
       "      <td>474</td>\n",
       "      <td>0.993748</td>\n",
       "      <td>3 years</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>486</td>\n",
       "      <td>510</td>\n",
       "      <td>0.930384</td>\n",
       "      <td>visual analytics machine</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>520</td>\n",
       "      <td>564</td>\n",
       "      <td>0.902822</td>\n",
       "      <td>data visualisation nlp data scienceexpertise</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>565</td>\n",
       "      <td>592</td>\n",
       "      <td>0.838013</td>\n",
       "      <td>natural language processing</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>616</td>\n",
       "      <td>638</td>\n",
       "      <td>0.586963</td>\n",
       "      <td>active learningminimum</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>639</td>\n",
       "      <td>646</td>\n",
       "      <td>0.778981</td>\n",
       "      <td>3 years</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>647</td>\n",
       "      <td>655</td>\n",
       "      <td>0.580869</td>\n",
       "      <td>research</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>656</td>\n",
       "      <td>663</td>\n",
       "      <td>0.652997</td>\n",
       "      <td>machine</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>673</td>\n",
       "      <td>732</td>\n",
       "      <td>0.817695</td>\n",
       "      <td>information visualisationproven industry experience machine</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>742</td>\n",
       "      <td>815</td>\n",
       "      <td>0.884746</td>\n",
       "      <td>information visualisationproficient pythonexperience research development</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>816</td>\n",
       "      <td>836</td>\n",
       "      <td>0.831204</td>\n",
       "      <td>large scale projects</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>845</td>\n",
       "      <td>868</td>\n",
       "      <td>0.532309</td>\n",
       "      <td>cybersecurityexperience</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>875</td>\n",
       "      <td>882</td>\n",
       "      <td>0.956170</td>\n",
       "      <td>machine</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>892</td>\n",
       "      <td>901</td>\n",
       "      <td>0.739934</td>\n",
       "      <td>libraries</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>906</td>\n",
       "      <td>951</td>\n",
       "      <td>0.792629</td>\n",
       "      <td>big data spacy gensim nltk sparkml experience</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>963</td>\n",
       "      <td>1007</td>\n",
       "      <td>0.949646</td>\n",
       "      <td>bespoke interactive data visualisation tools</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1014</td>\n",
       "      <td>1056</td>\n",
       "      <td>0.791885</td>\n",
       "      <td>d3js reactproven track record publications</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1057</td>\n",
       "      <td>1081</td>\n",
       "      <td>0.880277</td>\n",
       "      <td>top journals conferences</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1092</td>\n",
       "      <td>1096</td>\n",
       "      <td>0.549183</td>\n",
       "      <td>tvcg</td>\n",
       "      <td>4.203393e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    BeginOffset  EndOffset     Score  \\\n",
       "0             0         31  0.871532   \n",
       "1            41         55  0.847129   \n",
       "2            56         88  0.814921   \n",
       "3           103        124  0.996263   \n",
       "4           125        136  0.555494   \n",
       "5           146        168  0.885270   \n",
       "6           177        185  0.955149   \n",
       "7           186        213  0.814103   \n",
       "8           214        247  0.648581   \n",
       "9           257        267  0.484630   \n",
       "10          268        303  0.803846   \n",
       "11          304        324  0.757898   \n",
       "12          336        374  0.976523   \n",
       "13          382        390  0.975490   \n",
       "14          400        407  0.958755   \n",
       "15          417        459  0.735959   \n",
       "16          467        474  0.993748   \n",
       "17          486        510  0.930384   \n",
       "18          520        564  0.902822   \n",
       "19          565        592  0.838013   \n",
       "20          616        638  0.586963   \n",
       "21          639        646  0.778981   \n",
       "22          647        655  0.580869   \n",
       "23          656        663  0.652997   \n",
       "24          673        732  0.817695   \n",
       "25          742        815  0.884746   \n",
       "26          816        836  0.831204   \n",
       "27          845        868  0.532309   \n",
       "28          875        882  0.956170   \n",
       "29          892        901  0.739934   \n",
       "30          906        951  0.792629   \n",
       "31          963       1007  0.949646   \n",
       "32         1014       1056  0.791885   \n",
       "33         1057       1081  0.880277   \n",
       "34         1092       1096  0.549183   \n",
       "\n",
       "                                                                         Text  \\\n",
       "0                                             artificial intelligence machine   \n",
       "1                                                              data scientist   \n",
       "2                                            main duties responsibilities job   \n",
       "3                                                       stateoftheart methods   \n",
       "4                                                                 nlp machine   \n",
       "5                                                      aiapplying nlp methods   \n",
       "6                                                                    insights   \n",
       "7                                                 text email messagesapplying   \n",
       "8                                           supervised semisupervised machine   \n",
       "9                                                                  approaches   \n",
       "10                                        classification large scale datasets   \n",
       "11                                                       cybersecurity domain   \n",
       "12                                     bespoke interactive visualisation tool   \n",
       "13                                                                   endusers   \n",
       "14                                                                    machine   \n",
       "15                                 component skills qualifications experience   \n",
       "16                                                                    3 years   \n",
       "17                                                   visual analytics machine   \n",
       "18                               data visualisation nlp data scienceexpertise   \n",
       "19                                                natural language processing   \n",
       "20                                                     active learningminimum   \n",
       "21                                                                    3 years   \n",
       "22                                                                   research   \n",
       "23                                                                    machine   \n",
       "24                information visualisationproven industry experience machine   \n",
       "25  information visualisationproficient pythonexperience research development   \n",
       "26                                                       large scale projects   \n",
       "27                                                    cybersecurityexperience   \n",
       "28                                                                    machine   \n",
       "29                                                                  libraries   \n",
       "30                              big data spacy gensim nltk sparkml experience   \n",
       "31                               bespoke interactive data visualisation tools   \n",
       "32                                 d3js reactproven track record publications   \n",
       "33                                                   top journals conferences   \n",
       "34                                                                       tvcg   \n",
       "\n",
       "              id  \n",
       "0   4.203393e+09  \n",
       "1   4.203393e+09  \n",
       "2   4.203393e+09  \n",
       "3   4.203393e+09  \n",
       "4   4.203393e+09  \n",
       "5   4.203393e+09  \n",
       "6   4.203393e+09  \n",
       "7   4.203393e+09  \n",
       "8   4.203393e+09  \n",
       "9   4.203393e+09  \n",
       "10  4.203393e+09  \n",
       "11  4.203393e+09  \n",
       "12  4.203393e+09  \n",
       "13  4.203393e+09  \n",
       "14  4.203393e+09  \n",
       "15  4.203393e+09  \n",
       "16  4.203393e+09  \n",
       "17  4.203393e+09  \n",
       "18  4.203393e+09  \n",
       "19  4.203393e+09  \n",
       "20  4.203393e+09  \n",
       "21  4.203393e+09  \n",
       "22  4.203393e+09  \n",
       "23  4.203393e+09  \n",
       "24  4.203393e+09  \n",
       "25  4.203393e+09  \n",
       "26  4.203393e+09  \n",
       "27  4.203393e+09  \n",
       "28  4.203393e+09  \n",
       "29  4.203393e+09  \n",
       "30  4.203393e+09  \n",
       "31  4.203393e+09  \n",
       "32  4.203393e+09  \n",
       "33  4.203393e+09  \n",
       "34  4.203393e+09  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cln"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7d38ba",
   "metadata": {},
   "source": [
    "### Extract skills from AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f011a14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T06:50:58.300941Z",
     "start_time": "2022-05-08T06:40:14.199942Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_frac=1 # % of total records for sample processing.\n",
    "cf_score=0.4  # confidence score threshold for key phrases\n",
    "\n",
    "# Call AWS comprehend to extract key phrases\n",
    "\n",
    "comprehend = boto3.client(service_name='comprehend', region_name='us-east-2')\n",
    "                \n",
    "#text = \"It is raining today in Seattle\"\n",
    "\n",
    "print('Calling DetectKeyPhrases')\n",
    "#df=pd.DataFrame()\n",
    "df_list=[]\n",
    "\n",
    "for i in range(round(sample_frac*len(df_main))):\n",
    "    if len(main_df[\"description\"].iloc[i])<=5000: #AWS' limitation on one request\n",
    "        dump_json=json.dumps(comprehend.detect_key_phrases(Text=df_main[\"description\"].iloc[i]\n",
    "                                                       , LanguageCode='en'), sort_keys=True, indent=4)\n",
    "        df_phrases=pd.json_normalize(json.loads(dump_json)['KeyPhrases'])\n",
    "        df_phrases['id']=main_df[\"id\"].iloc[i]\n",
    "        df_list.append(df_phrases)\n",
    "\n",
    "    else:\n",
    "        None # to be handled\n",
    "        \n",
    "df=pd.concat(df_list)\n",
    "print('End of DetectKeyPhrases\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce344c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-07T11:54:46.272062Z",
     "start_time": "2022-05-07T11:54:46.227257Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate the dataframe of skills\n",
    "df_skills=pd.DataFrame(df[df['Score']>=cf_score][['id','Text']])\n",
    "df_skills.columns=['id','skill']\n",
    "df_skills['type']=''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6400f89f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T06:38:47.456084Z",
     "start_time": "2022-05-08T06:38:47.334198Z"
    }
   },
   "outputs": [],
   "source": [
    "df_skills=df_skills.groupby(['skill']).count()[df_skills.groupby(['skill']).count()['id']>20].sort_values('id',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afa4767",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T06:39:22.786395Z",
     "start_time": "2022-05-08T06:39:22.680923Z"
    }
   },
   "outputs": [],
   "source": [
    "d1 = dtale.show(df_skills)\n",
    "d1.open_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b2b398b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-12T09:54:28.399447Z",
     "start_time": "2022-05-12T09:54:25.323893Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 17:54:25,340 - INFO     - Request URL: 'https://topskills.cognitiveservices.azure.com/text/analytics/v3.2-preview.2/entities/recognition/general?stringIndexType=UnicodeCodePoint'\n",
      "Request method: 'POST'\n",
      "Request headers:\n",
      "    'Content-Type': 'application/json'\n",
      "    'Content-Length': '1223'\n",
      "    'Accept': 'application/json, text/json'\n",
      "    'x-ms-client-request-id': '818f2ed6-d1d9-11ec-8b90-acde48001122'\n",
      "    'User-Agent': 'azsdk-python-ai-textanalytics/5.2.0b3 Python/3.7.9 (Darwin-21.4.0-x86_64-i386-64bit)'\n",
      "    'Ocp-Apim-Subscription-Key': 'REDACTED'\n",
      "A body is sent with the request\n",
      "2022-05-12 17:54:27,221 - INFO     - Response status: 200\n",
      "Response headers:\n",
      "    'Transfer-Encoding': 'chunked'\n",
      "    'Content-Type': 'application/json; charset=utf-8'\n",
      "    'csp-billing-usage': 'REDACTED'\n",
      "    'x-envoy-upstream-service-time': '91'\n",
      "    'apim-request-id': 'a22130c6-f509-47ed-87ce-e01611a416e1'\n",
      "    'Strict-Transport-Security': 'max-age=31536000; includeSubDomains; preload'\n",
      "    'x-content-type-options': 'nosniff'\n",
      "    'Date': 'Thu, 12 May 2022 09:54:26 GMT'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>skill</th>\n",
       "      <th>category</th>\n",
       "      <th>confidence score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.203393e+09</td>\n",
       "      <td>artificial intelligence</td>\n",
       "      <td>Skill</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.203393e+09</td>\n",
       "      <td>machine learning</td>\n",
       "      <td>Skill</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.203393e+09</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>PersonType</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.203393e+09</td>\n",
       "      <td>machine learning</td>\n",
       "      <td>Skill</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.203393e+09</td>\n",
       "      <td>machine</td>\n",
       "      <td>Skill</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.203393e+09</td>\n",
       "      <td>cybersecurity</td>\n",
       "      <td>Skill</td>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.203393e+09</td>\n",
       "      <td>interactive</td>\n",
       "      <td>Skill</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.203393e+09</td>\n",
       "      <td>machine learning</td>\n",
       "      <td>Skill</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.203393e+09</td>\n",
       "      <td>3 years</td>\n",
       "      <td>DateTime</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.203393e+09</td>\n",
       "      <td>visual analytics</td>\n",
       "      <td>Skill</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.203393e+09</td>\n",
       "      <td>machine learning</td>\n",
       "      <td>Skill</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.203393e+09</td>\n",
       "      <td>data visualisation</td>\n",
       "      <td>Skill</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.203393e+09</td>\n",
       "      <td>data scienceexpertise</td>\n",
       "      <td>Skill</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.203393e+09</td>\n",
       "      <td>natural language processing</td>\n",
       "      <td>Skill</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4.203393e+09</td>\n",
       "      <td>visualisationsupported</td>\n",
       "      <td>Skill</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.203393e+09</td>\n",
       "      <td>active</td>\n",
       "      <td>Skill</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.203393e+09</td>\n",
       "      <td>3 years</td>\n",
       "      <td>DateTime</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.203393e+09</td>\n",
       "      <td>research</td>\n",
       "      <td>Skill</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.203393e+09</td>\n",
       "      <td>machine learning</td>\n",
       "      <td>Skill</td>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.203393e+09</td>\n",
       "      <td>information</td>\n",
       "      <td>Skill</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.203393e+09</td>\n",
       "      <td>pythonexperience</td>\n",
       "      <td>Product</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.203393e+09</td>\n",
       "      <td>research development</td>\n",
       "      <td>Skill</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.203393e+09</td>\n",
       "      <td>cybersecurityexperience</td>\n",
       "      <td>Skill</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.203393e+09</td>\n",
       "      <td>machine learning</td>\n",
       "      <td>Skill</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.203393e+09</td>\n",
       "      <td>interactive</td>\n",
       "      <td>Skill</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4.203393e+09</td>\n",
       "      <td>visualisation</td>\n",
       "      <td>Skill</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4.203393e+09</td>\n",
       "      <td>d3js</td>\n",
       "      <td>Product</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                        skill    category  confidence score\n",
       "0   4.203393e+09      artificial intelligence       Skill              0.88\n",
       "1   4.203393e+09             machine learning       Skill              0.64\n",
       "2   4.203393e+09               data scientist  PersonType              0.81\n",
       "3   4.203393e+09             machine learning       Skill              0.65\n",
       "4   4.203393e+09                      machine       Skill              0.64\n",
       "5   4.203393e+09                cybersecurity       Skill              0.66\n",
       "6   4.203393e+09                  interactive       Skill              0.58\n",
       "7   4.203393e+09             machine learning       Skill              0.64\n",
       "8   4.203393e+09                      3 years    DateTime              0.80\n",
       "9   4.203393e+09             visual analytics       Skill              0.89\n",
       "10  4.203393e+09             machine learning       Skill              0.87\n",
       "11  4.203393e+09           data visualisation       Skill              0.65\n",
       "12  4.203393e+09        data scienceexpertise       Skill              0.85\n",
       "13  4.203393e+09  natural language processing       Skill              0.86\n",
       "14  4.203393e+09       visualisationsupported       Skill              0.77\n",
       "15  4.203393e+09                       active       Skill              0.58\n",
       "16  4.203393e+09                      3 years    DateTime              0.80\n",
       "17  4.203393e+09                     research       Skill              0.50\n",
       "18  4.203393e+09             machine learning       Skill              0.68\n",
       "19  4.203393e+09                  information       Skill              0.60\n",
       "20  4.203393e+09             pythonexperience     Product              0.51\n",
       "21  4.203393e+09         research development       Skill              0.82\n",
       "22  4.203393e+09      cybersecurityexperience       Skill              0.76\n",
       "23  4.203393e+09             machine learning       Skill              0.75\n",
       "24  4.203393e+09                  interactive       Skill              0.71\n",
       "25  4.203393e+09                visualisation       Skill              0.91\n",
       "26  4.203393e+09                         d3js     Product              0.48"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call Azure text analytics to identify name entities\n",
    "\n",
    "credential = AzureKeyCredential(\"7ad266f033314fc2a29eb6f1da7e0a74\")\n",
    "endpoint=\"https://topskills.cognitiveservices.azure.com/\"\n",
    "\n",
    "text_analytics_client = TextAnalyticsClient(endpoint, credential)\n",
    "\n",
    "#df_list=[]\n",
    "df_list=pd.DataFrame(columns=['id','skill','category','confidence score'])\n",
    "i=2\n",
    "if i==2:\n",
    "    documents = [item for item in df_main['description_cln'][i:i+1]]\n",
    "    \n",
    "    response = text_analytics_client.recognize_entities(documents, language=\"en\")\n",
    "    result = [doc for doc in response if not doc.is_error]\n",
    "    #print(result)\n",
    "    for doc in result:\n",
    "        #print(doc)\n",
    "        for entity in doc.entities:\n",
    "            df_list=df_list.append({'id':df_main['id'].iloc[i],\n",
    "                                     'skill':entity.text,\n",
    "                                    'category':entity.category,\n",
    "                                    'confidence score':entity.confidence_score},ignore_index=True)\n",
    "            #df_list.append(df_phrases)\n",
    "        \n",
    "df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a4c26b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T03:15:02.507482Z",
     "start_time": "2022-05-08T03:15:02.479473Z"
    }
   },
   "outputs": [],
   "source": [
    "main_df['description'][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db369ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T03:59:42.038012Z",
     "start_time": "2022-05-08T03:59:36.583932Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_frac=0.01 # % of total records for sample processing.\n",
    "cf_score=0.8  # confidence score threshold for key phrases\n",
    "# Call Azure text analytics to identify name entities\n",
    "\n",
    "credential = AzureKeyCredential(\"7ad266f033314fc2a29eb6f1da7e0a74\")\n",
    "endpoint=\"https://topskills.cognitiveservices.azure.com/\"\n",
    "\n",
    "text_analytics_client = TextAnalyticsClient(endpoint, credential)\n",
    "\n",
    "#df_list=[]\n",
    "df_list=pd.DataFrame(columns=['id','skill','category','confidence score'])\n",
    "for i in range(round(sample_frac*len(main_df))):\n",
    "    documents = [item for item in main_df['description'][i:i+1]]\n",
    "    \n",
    "    response = text_analytics_client.recognize_entities(documents, language=\"en\")\n",
    "    result = [doc for doc in response if not doc.is_error]\n",
    "    #print(result)\n",
    "    for doc in result:\n",
    "        #print(doc)\n",
    "        for entity in doc.entities:\n",
    "            df_list=df_list.append({'id':main_df['id'].iloc[i],\n",
    "                                     'skill':entity.text,\n",
    "                                    'category':entity.category,\n",
    "                                    'confidence score':entity.confidence_score},ignore_index=True)\n",
    "            #df_list.append(df_phrases)\n",
    "        \n",
    "df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb75c23a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-08T04:06:48.773664Z",
     "start_time": "2022-05-08T04:06:48.684496Z"
    }
   },
   "outputs": [],
   "source": [
    "d = dtale.show(df_list)\n",
    "d.open_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ef04f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T10:07:25.284146Z",
     "start_time": "2022-05-09T10:07:25.145883Z"
    }
   },
   "outputs": [],
   "source": [
    "d0 = dtale.show(df_main)\n",
    "d0.open_browser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50c97cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
